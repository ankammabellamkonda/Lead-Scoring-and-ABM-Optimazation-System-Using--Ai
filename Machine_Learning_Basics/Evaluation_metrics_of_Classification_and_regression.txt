Classification 
--------------
1) Accuracy-Accuracy tells us what percentage of predictions the model got right. whether it will rain or not

56/100=0-56
acc=no of correct pred/total no of pred
If a model predicts whether a tumor is malignant or benign, and it makes 80 correct predictions out of 100 total predictions,

acc= 80/100

when to use?

works well when classes are balanced (e.g. equal no of malignant and benign cases)
55-m ,45-b
92-m,8-b

2)precision=TP/TP+FP/all positives

email-spam or not spam

out of all the spam emails how many of them are actually spam

45 instances- rain, 55-no rain
precision = correctly predicted whether a patient has a disease

total predicted as having the disease : 50
correctly predicted as disease (TP):45
predicted diseased but actually healthy (FP):5
precision=45/50=90

When to USe:
When false positives are costly or harmful
	ex-avoiding uncessary cancer treatments for healthy patients

3)Recall=tp/tp+fn

In the same medical test:

actual diseased patients:50
correctly identified diseased patients TP:45
diseased patients not identified FN:5

recall = true positive/actual positive

When to Use:

When false negatives are costly or harmful.
  -example: Detecting a serious disease (ex: cancer) where missing a case is dangerous.

Naive Bayes Algorithm
----------------------

Naive Bayes is a ml algorithm based on Bayes'Theorem, used primilarly for classification tasks. It is called "naive" because it assumes that all the features in a dataset are independent of each other, which is often not true in real life.Despite this assumption, it works surprisingly well for many real-world applications.

Bayes'Theorem(The Foundation of Naive Bayes)

Bayes'Theorem calculates the probability of a hypothesis based on prior knowledge of conditions related to the hypothesis

P(A/B) = P(B/A) * P(A)/P(B)

P(B/A): Probability of event B given that A is true.(likehood)

P(A): probability of event A occurring. (Prior Probability)

P(B): Probability of event B occurring. (Evidence)

How does naive bayes algo works?

Problem: classify if a given email is spam or notspam

Dataset:

------------------------------------------------------------------------

Email Id contains"Free" contains "offer" spam (1) or notspam (0)

1		yes		no 		0

2		yes		yes		1

3		no 		yes		0

4		yes 		yes 		1

-----------------------------------------------------------------------

P(spam) = 2/4 = 0.5

p(notspam) = 2/4 = 0.5

Likehoods for "contains Free"

p(free/spam)=2/2=1

p(free/notspam)=1/2=0.5
------------------------------------
Likehood for "contains offer"

p(offer/spam)=2/2=1

p(offer/notspam)=1/2=0.5

Applications:
-------------

spam email detection, sentiment analysis, medical diagnosis, news classification


Regression:
------------

1.Mean Absolute Error
MAE measures the average magnitude of errors in predictions, ignoring their direction. 
MAE = 1/N * sum([ACTUAL-PREDICTED])

Example:
If actual values are [3,5,7] and predictions are [4,4,6]:
MAE=(|1|+|1|+|1|])/3=1
used for simple error magnitude calculation

2.Mean squared error - MSE  
MSE = 1/n*(actual-predicted)**2
ACTUAL = 3,5,9,11
PREDICTED = 13,10,16,12

MAE,MSE,RMSE

RMSE = sq root(MSE)
rmse represents the same units of data

R2 score (coefficient of Determination)

R2 = 1 - (SSE)/TSS
SSE = SUM(actual-pred)*2 --> sum of squared error
TSS = total sum of squares = sum(actual-mean(actual)*2

1)sse = tss->0
2)sse=0-->1
2,2,2->2,2,2





 








































